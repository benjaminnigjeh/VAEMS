{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BAGdx5ZRmHS4",
        "1JrMyKVa8RG-"
      ],
      "authorship_tag": "ABX9TyMPyV85z7hzhJGqONDzZEWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminnigjeh/VAEMS/blob/main/FCVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and dependencies"
      ],
      "metadata": {
        "id": "BAGdx5ZRmHS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mjjSfOH_mDpF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import TensorBoard\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the tensorboard callback function"
      ],
      "metadata": {
        "id": "1JrMyKVa8RG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"Unsupervised_clustering\"\n",
        "tensorboard = TensorBoard(\n",
        "    log_dir='/content/{}'.format(NAME))"
      ],
      "metadata": {
        "id": "Hz4kKRYsmixS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload dataset from a local folder\n",
        "\n",
        "the number of features is equal to n_dim squared"
      ],
      "metadata": {
        "id": "Yf0ia7ufn9-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_dim = 88\n",
        "dataset = files.upload_file('dataset')\n",
        "df = pd.read_csv('/content/dataset')\n",
        "X = df.copy()\n",
        "Y = X.pop(\"target\")\n",
        "X_np = np.array(X)\n",
        "x_train = np.reshape(X_np,(-1, n_dim, n_dim, 1))\n",
        "y_train = np.array(Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ii4XkJHFm0uD",
        "outputId": "a908746b-98fa-4074-c3c8-9304973f8db9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b7cb01fe-c669-4a18-8cfa-c1d1acfe8006\" name=\"files[]\"  disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b7cb01fe-c669-4a18-8cfa-c1d1acfe8006\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pancreatic_tissue.csv to /content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the n dimensions for the latent space"
      ],
      "metadata": {
        "id": "yqAg35Nn8vrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "ifdJx7Xx8tfi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder and decoder architure and VAE class"
      ],
      "metadata": {
        "id": "gcFPhe46wVmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = keras.Input(shape=(n_dim, n_dim, 1))\n",
        "x = layers.Flatten()(encoder_inputs)\n",
        "x = layers.Dense(120 , activation=\"relu\")(x)\n",
        "x = layers.Dense(120 , activation=\"relu\")(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(n_dim * n_dim * 1, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Dense(n_dim * n_dim * 1, activation=\"sigmoid\")(x)\n",
        "decoder_outputs = layers.Reshape((n_dim, n_dim, 1))(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M4B9PXOporvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f49bce-c7c4-434b-9bc1-00603dea12f3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)       [(None, 88, 88, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)         (None, 7744)                 0         ['input_15[0][0]']            \n",
            "                                                                                                  \n",
            " dense_35 (Dense)            (None, 120)                  929400    ['flatten_7[0][0]']           \n",
            "                                                                                                  \n",
            " dense_36 (Dense)            (None, 120)                  14520     ['dense_35[0][0]']            \n",
            "                                                                                                  \n",
            " dense_37 (Dense)            (None, 16)                   1936      ['dense_36[0][0]']            \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 2)                    34        ['dense_37[0][0]']            \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 2)                    34        ['dense_37[0][0]']            \n",
            "                                                                                                  \n",
            " sampling_7 (Sampling)       (None, 2)                    0         ['z_mean[0][0]',              \n",
            "                                                                     'z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 945924 (3.61 MB)\n",
            "Trainable params: 945924 (3.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 7744)              23232     \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 7744)              59977280  \n",
            "                                                                 \n",
            " reshape_7 (Reshape)         (None, 88, 88, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60000512 (228.88 MB)\n",
            "Trainable params: 60000512 (228.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "OSfrB378wmG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(x_train, epochs=200, callbacks=[tensorboard])\n",
        "\n",
        "def plot_label_clusters(vae, data, labels):\n",
        "    z_mean, _, _ = vae.encoder.predict(data)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()\n",
        "plot_label_clusters(vae, x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oRD37A2IwRyR",
        "outputId": "1e8d95e5-74d5-4c19-e695-583f384b9473"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 10s 3s/step - loss: 5015.0334 - reconstruction_loss: 5007.6523 - kl_loss: 30.5670\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 5025.1834 - reconstruction_loss: 4988.0859 - kl_loss: 18.6926\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4939.2668 - reconstruction_loss: 4915.2163 - kl_loss: 32.2262\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4896.4710 - reconstruction_loss: 4881.1172 - kl_loss: 20.6270\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4909.6108 - reconstruction_loss: 4887.7773 - kl_loss: 13.0439\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4889.8986 - reconstruction_loss: 4877.9722 - kl_loss: 17.3698\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4881.5796 - reconstruction_loss: 4873.8428 - kl_loss: 11.0318\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4874.1719 - reconstruction_loss: 4855.4805 - kl_loss: 11.3890\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4867.4554 - reconstruction_loss: 4859.6650 - kl_loss: 10.3521\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4862.1055 - reconstruction_loss: 4861.7754 - kl_loss: 7.3806\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4865.9229 - reconstruction_loss: 4849.0776 - kl_loss: 7.9157\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4860.8257 - reconstruction_loss: 4847.7109 - kl_loss: 7.3264\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4844.2842 - reconstruction_loss: 4836.7974 - kl_loss: 7.2844\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4827.5399 - reconstruction_loss: 4820.0615 - kl_loss: 7.4062\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4808.3270 - reconstruction_loss: 4797.2837 - kl_loss: 8.1287\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4787.1660 - reconstruction_loss: 4767.5015 - kl_loss: 7.9607\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4778.5625 - reconstruction_loss: 4770.8418 - kl_loss: 8.4081\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4784.1440 - reconstruction_loss: 4771.9336 - kl_loss: 8.9574\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4779.9785 - reconstruction_loss: 4767.3613 - kl_loss: 8.8990\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4780.9657 - reconstruction_loss: 4758.9639 - kl_loss: 8.1216\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 4s 3s/step - loss: 4777.1025 - reconstruction_loss: 4779.8242 - kl_loss: 7.6336\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4787.5783 - reconstruction_loss: 4773.9375 - kl_loss: 9.1418\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4776.2620 - reconstruction_loss: 4785.1797 - kl_loss: 6.6800\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4772.4728 - reconstruction_loss: 4766.7969 - kl_loss: 8.0711\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4777.7215 - reconstruction_loss: 4762.0322 - kl_loss: 7.9726\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4776.0793 - reconstruction_loss: 4761.6377 - kl_loss: 6.5783\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4767.0752 - reconstruction_loss: 4758.6562 - kl_loss: 7.9103\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4760.6204 - reconstruction_loss: 4764.6533 - kl_loss: 7.4872\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4767.4772 - reconstruction_loss: 4758.4697 - kl_loss: 6.3893\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4758.0540 - reconstruction_loss: 4758.7515 - kl_loss: 7.3392\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4765.8797 - reconstruction_loss: 4749.6689 - kl_loss: 7.4267\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4760.5990 - reconstruction_loss: 4754.2275 - kl_loss: 6.3702\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4761.0540 - reconstruction_loss: 4744.4976 - kl_loss: 6.8549\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4757.7139 - reconstruction_loss: 4748.1426 - kl_loss: 7.2550\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4748.4513 - reconstruction_loss: 4754.1343 - kl_loss: 6.6890\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4754.0117 - reconstruction_loss: 4749.2563 - kl_loss: 6.4220\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4752.4920 - reconstruction_loss: 4746.4395 - kl_loss: 6.8649\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4749.4338 - reconstruction_loss: 4746.3296 - kl_loss: 6.8427\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4745.7454 - reconstruction_loss: 4754.2949 - kl_loss: 6.1938\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4752.5591 - reconstruction_loss: 4736.3916 - kl_loss: 6.8576\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4752.2056 - reconstruction_loss: 4738.1064 - kl_loss: 7.1736\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 4s 1s/step - loss: 4750.0591 - reconstruction_loss: 4740.7773 - kl_loss: 7.0818\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4742.8330 - reconstruction_loss: 4745.0596 - kl_loss: 6.5128\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4744.7962 - reconstruction_loss: 4742.3262 - kl_loss: 6.7627\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4749.1641 - reconstruction_loss: 4733.0439 - kl_loss: 6.8806\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4741.0306 - reconstruction_loss: 4741.3691 - kl_loss: 6.5782\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4747.4920 - reconstruction_loss: 4730.8789 - kl_loss: 6.7939\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4742.6182 - reconstruction_loss: 4734.6084 - kl_loss: 6.7241\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4744.5257 - reconstruction_loss: 4730.4517 - kl_loss: 6.4442\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4742.4902 - reconstruction_loss: 4734.8066 - kl_loss: 6.4814\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4737.6729 - reconstruction_loss: 4737.6445 - kl_loss: 6.6143\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4742.5622 - reconstruction_loss: 4729.6172 - kl_loss: 6.3626\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4735.4956 - reconstruction_loss: 4737.8438 - kl_loss: 6.3031\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4741.2235 - reconstruction_loss: 4735.1870 - kl_loss: 6.4219\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4745.5601 - reconstruction_loss: 4723.9238 - kl_loss: 6.7046\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4742.0620 - reconstruction_loss: 4735.6128 - kl_loss: 6.6979\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4740.9001 - reconstruction_loss: 4736.3047 - kl_loss: 6.0973\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4740.4245 - reconstruction_loss: 4728.1030 - kl_loss: 6.6700\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4737.6073 - reconstruction_loss: 4729.9707 - kl_loss: 6.7634\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4737.6896 - reconstruction_loss: 4734.4209 - kl_loss: 6.1593\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4746.5355 - reconstruction_loss: 4722.7256 - kl_loss: 6.7894\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4745.0907 - reconstruction_loss: 4729.5181 - kl_loss: 6.2026\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4736.8296 - reconstruction_loss: 4732.3662 - kl_loss: 6.7325\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4739.7821 - reconstruction_loss: 4730.5708 - kl_loss: 7.2903\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4740.6810 - reconstruction_loss: 4721.2793 - kl_loss: 6.6540\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4735.7585 - reconstruction_loss: 4728.9243 - kl_loss: 6.4835\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4736.6121 - reconstruction_loss: 4735.6533 - kl_loss: 7.1367\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4735.9990 - reconstruction_loss: 4730.5635 - kl_loss: 6.9286\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4736.7677 - reconstruction_loss: 4723.6602 - kl_loss: 6.8302\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4727.8841 - reconstruction_loss: 4728.1348 - kl_loss: 6.9115\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4738.7635 - reconstruction_loss: 4711.8135 - kl_loss: 7.1677\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4731.7975 - reconstruction_loss: 4720.4097 - kl_loss: 6.7777\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4734.5312 - reconstruction_loss: 4713.2471 - kl_loss: 6.8991\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4722.8094 - reconstruction_loss: 4726.5107 - kl_loss: 6.7001\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4729.7726 - reconstruction_loss: 4716.0068 - kl_loss: 6.6518\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4728.4302 - reconstruction_loss: 4715.8994 - kl_loss: 6.8105\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4720.5929 - reconstruction_loss: 4728.5078 - kl_loss: 6.7330\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4724.5301 - reconstruction_loss: 4722.7124 - kl_loss: 6.8513\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4728.5610 - reconstruction_loss: 4720.0181 - kl_loss: 6.9006\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4723.9222 - reconstruction_loss: 4726.9336 - kl_loss: 6.6990\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4734.4201 - reconstruction_loss: 4711.9629 - kl_loss: 6.8263\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4728.9256 - reconstruction_loss: 4719.1689 - kl_loss: 6.8414\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4733.0400 - reconstruction_loss: 4718.3506 - kl_loss: 6.9495\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4731.5197 - reconstruction_loss: 4714.5752 - kl_loss: 7.0475\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4723.3195 - reconstruction_loss: 4716.8926 - kl_loss: 6.8326\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4729.6891 - reconstruction_loss: 4708.6484 - kl_loss: 7.1443\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4723.3415 - reconstruction_loss: 4719.6582 - kl_loss: 6.9453\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4730.8184 - reconstruction_loss: 4707.1230 - kl_loss: 7.1002\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4719.8076 - reconstruction_loss: 4718.9082 - kl_loss: 6.5000\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4719.1637 - reconstruction_loss: 4722.0020 - kl_loss: 6.6019\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4718.4738 - reconstruction_loss: 4721.7197 - kl_loss: 6.7549\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4729.3184 - reconstruction_loss: 4708.6763 - kl_loss: 6.9935\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4722.9469 - reconstruction_loss: 4718.7646 - kl_loss: 6.6240\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4726.2087 - reconstruction_loss: 4709.5264 - kl_loss: 6.9574\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4723.2790 - reconstruction_loss: 4715.6787 - kl_loss: 6.8604\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4727.2581 - reconstruction_loss: 4710.5210 - kl_loss: 7.0745\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4725.7687 - reconstruction_loss: 4706.2310 - kl_loss: 7.0266\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4720.4580 - reconstruction_loss: 4714.3691 - kl_loss: 6.5255\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4730.3857 - reconstruction_loss: 4703.9561 - kl_loss: 6.7343\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4726.4289 - reconstruction_loss: 4710.6406 - kl_loss: 7.3033\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4720.3896 - reconstruction_loss: 4714.6895 - kl_loss: 6.5160\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4715.3804 - reconstruction_loss: 4722.9072 - kl_loss: 6.3878\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4720.0044 - reconstruction_loss: 4716.7275 - kl_loss: 7.3515\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4713.6157 - reconstruction_loss: 4721.1035 - kl_loss: 6.8731\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4717.2855 - reconstruction_loss: 4722.6865 - kl_loss: 6.5133\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4720.0970 - reconstruction_loss: 4711.1978 - kl_loss: 7.2013\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4720.9256 - reconstruction_loss: 4717.2480 - kl_loss: 7.2032\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4720.2384 - reconstruction_loss: 4722.0586 - kl_loss: 6.9432\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4718.9406 - reconstruction_loss: 4710.2119 - kl_loss: 7.0442\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4711.3630 - reconstruction_loss: 4722.2080 - kl_loss: 7.1620\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4710.5163 - reconstruction_loss: 4717.0024 - kl_loss: 6.7634\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4719.0260 - reconstruction_loss: 4706.8682 - kl_loss: 7.0781\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4713.7267 - reconstruction_loss: 4709.9912 - kl_loss: 7.1996\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4713.6515 - reconstruction_loss: 4711.5029 - kl_loss: 6.7918\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4721.4297 - reconstruction_loss: 4710.4541 - kl_loss: 7.0781\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4716.2731 - reconstruction_loss: 4709.6333 - kl_loss: 7.2829\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4710.4959 - reconstruction_loss: 4715.0166 - kl_loss: 6.6261\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4718.6382 - reconstruction_loss: 4711.5625 - kl_loss: 6.7043\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4724.0381 - reconstruction_loss: 4702.6890 - kl_loss: 7.4571\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4720.2280 - reconstruction_loss: 4702.3555 - kl_loss: 7.2121\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4716.7264 - reconstruction_loss: 4711.6089 - kl_loss: 6.8522\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4715.7946 - reconstruction_loss: 4708.1963 - kl_loss: 7.2734\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4715.1292 - reconstruction_loss: 4704.7676 - kl_loss: 7.3279\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4724.8618 - reconstruction_loss: 4694.1738 - kl_loss: 6.8691\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4720.3379 - reconstruction_loss: 4700.6655 - kl_loss: 6.7764\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4720.0549 - reconstruction_loss: 4702.8882 - kl_loss: 7.1353\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4705.5794 - reconstruction_loss: 4712.2959 - kl_loss: 7.0166\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4713.8057 - reconstruction_loss: 4706.7080 - kl_loss: 7.0557\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4707.0632 - reconstruction_loss: 4710.8188 - kl_loss: 7.2193\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4713.1927 - reconstruction_loss: 4714.3037 - kl_loss: 7.2844\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4712.9914 - reconstruction_loss: 4708.8066 - kl_loss: 7.1152\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4723.9425 - reconstruction_loss: 4707.6162 - kl_loss: 7.2016\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4722.6294 - reconstruction_loss: 4709.8350 - kl_loss: 6.4527\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4716.2666 - reconstruction_loss: 4717.3564 - kl_loss: 6.3279\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4719.3081 - reconstruction_loss: 4717.9189 - kl_loss: 7.2221\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4723.4006 - reconstruction_loss: 4713.2666 - kl_loss: 6.4647\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4724.9738 - reconstruction_loss: 4701.6240 - kl_loss: 6.9873\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4728.3315 - reconstruction_loss: 4699.6675 - kl_loss: 7.1382\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4718.1483 - reconstruction_loss: 4710.5020 - kl_loss: 7.0198\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4720.6834 - reconstruction_loss: 4713.0605 - kl_loss: 7.0013\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4718.9025 - reconstruction_loss: 4708.9561 - kl_loss: 7.5570\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4715.5549 - reconstruction_loss: 4701.4072 - kl_loss: 7.4828\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4717.9753 - reconstruction_loss: 4701.2031 - kl_loss: 7.0851\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4718.0874 - reconstruction_loss: 4705.8037 - kl_loss: 8.0106\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4722.9076 - reconstruction_loss: 4702.0547 - kl_loss: 7.6217\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4715.7703 - reconstruction_loss: 4713.0537 - kl_loss: 7.3161\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4712.4668 - reconstruction_loss: 4708.4883 - kl_loss: 7.5758\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4705.6128 - reconstruction_loss: 4718.9639 - kl_loss: 7.2287\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4717.2344 - reconstruction_loss: 4709.7402 - kl_loss: 6.8517\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4711.9924 - reconstruction_loss: 4705.6909 - kl_loss: 6.9677\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4712.5492 - reconstruction_loss: 4708.1543 - kl_loss: 7.1692\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4704.9797 - reconstruction_loss: 4709.7715 - kl_loss: 6.8199\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4710.1037 - reconstruction_loss: 4699.9375 - kl_loss: 7.1344\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4711.5327 - reconstruction_loss: 4698.1440 - kl_loss: 7.3329\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4705.6883 - reconstruction_loss: 4709.9556 - kl_loss: 7.3639\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4702.5540 - reconstruction_loss: 4710.4365 - kl_loss: 6.9090\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4712.0505 - reconstruction_loss: 4698.7510 - kl_loss: 6.9533\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4714.5732 - reconstruction_loss: 4696.2617 - kl_loss: 7.2463\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4713.3447 - reconstruction_loss: 4699.0786 - kl_loss: 7.2525\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4714.7218 - reconstruction_loss: 4696.1611 - kl_loss: 7.0597\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4704.4458 - reconstruction_loss: 4707.3633 - kl_loss: 6.9810\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4708.8333 - reconstruction_loss: 4698.9663 - kl_loss: 7.0802\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4699.9969 - reconstruction_loss: 4709.0815 - kl_loss: 6.9456\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4708.6829 - reconstruction_loss: 4697.7041 - kl_loss: 6.9380\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4718.6662 - reconstruction_loss: 4689.1777 - kl_loss: 7.3825\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4703.1003 - reconstruction_loss: 4708.9180 - kl_loss: 6.6022\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4702.9608 - reconstruction_loss: 4711.4810 - kl_loss: 6.5906\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4713.4917 - reconstruction_loss: 4703.3486 - kl_loss: 6.9617\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4713.2926 - reconstruction_loss: 4690.3418 - kl_loss: 7.0723\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4708.3621 - reconstruction_loss: 4697.9365 - kl_loss: 6.7913\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4705.4842 - reconstruction_loss: 4701.9473 - kl_loss: 7.3172\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4713.6351 - reconstruction_loss: 4691.1748 - kl_loss: 7.4256\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4714.7646 - reconstruction_loss: 4699.3096 - kl_loss: 7.0949\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4727.6204 - reconstruction_loss: 4705.6006 - kl_loss: 7.6628\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4718.9007 - reconstruction_loss: 4712.0537 - kl_loss: 7.1581\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4712.1751 - reconstruction_loss: 4724.1348 - kl_loss: 7.4825\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4710.4456 - reconstruction_loss: 4716.0405 - kl_loss: 6.9930\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4717.4186 - reconstruction_loss: 4705.0928 - kl_loss: 7.2066\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4718.5789 - reconstruction_loss: 4711.3193 - kl_loss: 6.3397\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4707.7342 - reconstruction_loss: 4699.0327 - kl_loss: 6.7238\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4717.8587 - reconstruction_loss: 4694.2266 - kl_loss: 7.3656\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4726.1592 - reconstruction_loss: 4697.9248 - kl_loss: 6.8458\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4718.0443 - reconstruction_loss: 4721.9585 - kl_loss: 7.1975\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4723.3660 - reconstruction_loss: 4720.0903 - kl_loss: 7.1240\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4712.9595 - reconstruction_loss: 4703.2490 - kl_loss: 7.0624\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4714.2464 - reconstruction_loss: 4709.3730 - kl_loss: 6.4036\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4707.7100 - reconstruction_loss: 4701.6416 - kl_loss: 7.3696\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4716.8895 - reconstruction_loss: 4715.3311 - kl_loss: 8.1890\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4728.5223 - reconstruction_loss: 4709.4453 - kl_loss: 7.2001\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4714.0358 - reconstruction_loss: 4716.8506 - kl_loss: 7.6182\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4719.5736 - reconstruction_loss: 4712.7012 - kl_loss: 7.3197\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4715.8901 - reconstruction_loss: 4709.1235 - kl_loss: 6.7340\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4719.5373 - reconstruction_loss: 4707.2539 - kl_loss: 6.6741\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4715.9185 - reconstruction_loss: 4698.3296 - kl_loss: 6.9259\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4715.5579 - reconstruction_loss: 4694.6025 - kl_loss: 7.5449\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4706.0771 - reconstruction_loss: 4700.8643 - kl_loss: 6.8775\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4700.4188 - reconstruction_loss: 4706.5835 - kl_loss: 6.5687\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4705.4878 - reconstruction_loss: 4698.3965 - kl_loss: 6.7574\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 3s 1s/step - loss: 4707.7104 - reconstruction_loss: 4692.0420 - kl_loss: 7.1332\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4707.7324 - reconstruction_loss: 4695.0361 - kl_loss: 7.1584\n",
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimation of euclidian distance in the binary clusters"
      ],
      "metadata": {
        "id": "5dw4BADBwzQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "length = len(y_train)\n",
        "\n",
        "for i in range(0, length, 1):\n",
        "    b = np.reshape(x_train[i], (1, n_dim, n_dim, 1))\n",
        "    z_mean, _, _ = vae.encoder.predict(b)\n",
        "    c = np.array([[z_mean[:, 0], z_mean[:, 1]]])\n",
        "    c = np.reshape(c, (2, 1))\n",
        "    c = np.transpose(c)\n",
        "    data.append(c)\n",
        "\n",
        "data = np.array(data)\n",
        "data = np.reshape(data, (length, 2))\n",
        "y_train_label = np.reshape(y_train, (length, 1))\n",
        "data = np.concatenate((data, y_train_label), axis=1)\n",
        "means_cluster_1 = data[0:int(length/2), :2].mean(axis=0)\n",
        "means_cluster_2 = data[int(length/2):length+1, :2].mean(axis=0)\n",
        "dist = np.linalg.norm(means_cluster_1-means_cluster_2)\n",
        "print(\"Euclidian distance is \", dist)"
      ],
      "metadata": {
        "id": "80pLH78Lww0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}