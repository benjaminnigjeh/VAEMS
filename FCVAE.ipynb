{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BAGdx5ZRmHS4",
        "1JrMyKVa8RG-"
      ],
      "authorship_tag": "ABX9TyMBwV4K5cLVExBT8hk/U7h+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminnigjeh/VAEMS/blob/main/FCVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and dependencies"
      ],
      "metadata": {
        "id": "BAGdx5ZRmHS4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mjjSfOH_mDpF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import TensorBoard\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the tensorboard callback function"
      ],
      "metadata": {
        "id": "1JrMyKVa8RG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"Unsupervised_clustering\"\n",
        "tensorboard = TensorBoard(\n",
        "    log_dir='/content/{}'.format(NAME))"
      ],
      "metadata": {
        "id": "Hz4kKRYsmixS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload dataset from a local folder\n",
        "\n",
        "the number of features is equal to n_dim squared"
      ],
      "metadata": {
        "id": "Yf0ia7ufn9-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_dim = 88\n",
        "dataset = files.upload_file('dataset')\n",
        "df = pd.read_csv('/content/dataset')\n",
        "X = df.copy()\n",
        "Y = X.pop(\"target\")\n",
        "X_np = np.array(X)\n",
        "x_train = np.reshape(X_np,(-1, n_dim, n_dim, 1))\n",
        "y_train = np.array(Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ii4XkJHFm0uD",
        "outputId": "e510c64c-feff-4073-94b3-9076caff4cd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-87ead3a3-0c36-4bab-b832-40caab1db15e\" name=\"files[]\"  disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-87ead3a3-0c36-4bab-b832-40caab1db15e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved pancreatic_tissue.csv to /content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the n dimensions for the latent space"
      ],
      "metadata": {
        "id": "yqAg35Nn8vrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 2\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "ifdJx7Xx8tfi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder and decoder architure and VAE class"
      ],
      "metadata": {
        "id": "gcFPhe46wVmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = keras.Input(shape=(n_dim, n_dim, 1))\n",
        "x = layers.Flatten()(encoder_inputs)\n",
        "x = layers.Dense(120 , activation=\"relu\")(x)\n",
        "x = layers.Dense(120 , activation=\"relu\")(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(n_dim * n_dim * 1, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Dense(n_dim * n_dim * 1, activation=\"sigmoid\")(x)\n",
        "decoder_outputs = layers.Reshape((n_dim, n_dim, 1))(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M4B9PXOporvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58f5c8a-77c9-41a9-eefa-a52899ce428a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 88, 88, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 7744)                 0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 120)                  929400    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 120)                  14520     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 16)                   1936      ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 2)                    34        ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 2)                    34        ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " sampling (Sampling)         (None, 2)                    0         ['z_mean[0][0]',              \n",
            "                                                                     'z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 945924 (3.61 MB)\n",
            "Trainable params: 945924 (3.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 7744)              23232     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 7744)              59977280  \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 88, 88, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60000512 (228.88 MB)\n",
            "Trainable params: 60000512 (228.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "OSfrB378wmG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(x_train, epochs=500, callbacks=[tensorboard])\n",
        "\n",
        "def plot_label_clusters(vae, data, labels):\n",
        "    z_mean, _, _ = vae.encoder.predict(data)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()\n",
        "plot_label_clusters(vae, x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oRD37A2IwRyR",
        "outputId": "565904be-5745-4f70-ca9a-257dcce1c22c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 3s 608ms/step - loss: 4867.9798 - reconstruction_loss: 4922.2212 - kl_loss: 6.5958\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 4791.5758 - reconstruction_loss: 4776.0605 - kl_loss: 8.0902\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 4873.1943 - reconstruction_loss: 4848.6562 - kl_loss: 10.3175\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 4772.0861 - reconstruction_loss: 4764.5317 - kl_loss: 9.0694\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 2s 889ms/step - loss: 4797.0130 - reconstruction_loss: 4802.4170 - kl_loss: 7.6595\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 4788.5617 - reconstruction_loss: 4774.0742 - kl_loss: 7.6341\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 1s 590ms/step - loss: 4743.8237 - reconstruction_loss: 4751.2207 - kl_loss: 8.4881\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4753.5776 - reconstruction_loss: 4761.3789 - kl_loss: 9.4447\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 4758.3892 - reconstruction_loss: 4753.1416 - kl_loss: 9.3137\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 4751.5090 - reconstruction_loss: 4736.5547 - kl_loss: 8.7622\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 4744.1968 - reconstruction_loss: 4743.8154 - kl_loss: 8.3080\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 4756.4181 - reconstruction_loss: 4736.5654 - kl_loss: 8.0478\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 1s 645ms/step - loss: 4747.0521 - reconstruction_loss: 4732.3340 - kl_loss: 8.3567\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 2s 763ms/step - loss: 4741.8796 - reconstruction_loss: 4730.6035 - kl_loss: 8.7454\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 4741.7567 - reconstruction_loss: 4736.5479 - kl_loss: 9.0765\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 1s 603ms/step - loss: 4734.7778 - reconstruction_loss: 4739.8662 - kl_loss: 8.9753\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 4741.4515 - reconstruction_loss: 4725.8701 - kl_loss: 8.3205\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 4739.2065 - reconstruction_loss: 4730.7119 - kl_loss: 8.0997\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 4739.6455 - reconstruction_loss: 4723.4111 - kl_loss: 8.4915\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 4730.8604 - reconstruction_loss: 4733.8271 - kl_loss: 8.7250\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 4728.0007 - reconstruction_loss: 4733.4678 - kl_loss: 8.4328\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 1s 684ms/step - loss: 4736.9591 - reconstruction_loss: 4735.1211 - kl_loss: 8.0960\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 2s 741ms/step - loss: 4740.1785 - reconstruction_loss: 4719.7808 - kl_loss: 8.1153\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 4736.3670 - reconstruction_loss: 4721.6143 - kl_loss: 8.2773\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 4732.0378 - reconstruction_loss: 4727.2256 - kl_loss: 8.2879\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 4734.3394 - reconstruction_loss: 4722.3428 - kl_loss: 8.1154\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4737.7770 - reconstruction_loss: 4720.1143 - kl_loss: 8.2098\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 4740.3835 - reconstruction_loss: 4714.9600 - kl_loss: 8.1615\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 4724.5610 - reconstruction_loss: 4733.3745 - kl_loss: 8.1038\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 4731.5060 - reconstruction_loss: 4723.7676 - kl_loss: 8.0947\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 1s 749ms/step - loss: 4733.2749 - reconstruction_loss: 4721.4185 - kl_loss: 8.1369\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 2s 724ms/step - loss: 4734.1193 - reconstruction_loss: 4725.9854 - kl_loss: 7.9579\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 4733.7013 - reconstruction_loss: 4721.9316 - kl_loss: 7.9671\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 4733.3413 - reconstruction_loss: 4729.5645 - kl_loss: 7.9921\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 4724.2062 - reconstruction_loss: 4732.2017 - kl_loss: 8.1902\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 4730.7516 - reconstruction_loss: 4724.6758 - kl_loss: 7.9200\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 4733.0620 - reconstruction_loss: 4722.9043 - kl_loss: 7.8120\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 4737.2715 - reconstruction_loss: 4717.6665 - kl_loss: 7.7422\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 4727.5991 - reconstruction_loss: 4731.5732 - kl_loss: 7.6958\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 1s 798ms/step - loss: 4731.9386 - reconstruction_loss: 4726.0859 - kl_loss: 7.9689\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 2s 651ms/step - loss: 4728.3221 - reconstruction_loss: 4728.9121 - kl_loss: 7.7732\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 4734.2712 - reconstruction_loss: 4720.8032 - kl_loss: 7.6944\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 1s 740ms/step - loss: 4729.9984 - reconstruction_loss: 4725.4810 - kl_loss: 7.9557\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 4732.2777 - reconstruction_loss: 4723.3916 - kl_loss: 7.8238\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4722.6554 - reconstruction_loss: 4732.4331 - kl_loss: 7.6826\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 4735.5636 - reconstruction_loss: 4715.3809 - kl_loss: 7.7402\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4732.0552 - reconstruction_loss: 4718.1328 - kl_loss: 7.7274\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 4735.1317 - reconstruction_loss: 4716.2363 - kl_loss: 7.4903\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 2s 872ms/step - loss: 4733.7012 - reconstruction_loss: 4720.0474 - kl_loss: 7.7428\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 4726.8517 - reconstruction_loss: 4738.7290 - kl_loss: 7.8078\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 4734.9188 - reconstruction_loss: 4719.5283 - kl_loss: 7.4029\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 1s 592ms/step - loss: 4732.2204 - reconstruction_loss: 4720.3252 - kl_loss: 7.7871\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 1s 599ms/step - loss: 4730.5070 - reconstruction_loss: 4724.0527 - kl_loss: 7.7186\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 4741.7860 - reconstruction_loss: 4708.4243 - kl_loss: 7.2782\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4726.5794 - reconstruction_loss: 4724.4229 - kl_loss: 7.5770\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 5s 2s/step - loss: 4727.5698 - reconstruction_loss: 4726.4492 - kl_loss: 7.5648\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4734.4780 - reconstruction_loss: 4713.6299 - kl_loss: 7.4700\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 2s 695ms/step - loss: 4725.6611 - reconstruction_loss: 4726.1772 - kl_loss: 7.5228\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4725.8919 - reconstruction_loss: 4723.4355 - kl_loss: 7.3624\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4725.4046 - reconstruction_loss: 4725.7500 - kl_loss: 7.4353\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4723.4473 - reconstruction_loss: 4726.8818 - kl_loss: 7.3833\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 2s 821ms/step - loss: 4730.5858 - reconstruction_loss: 4724.2812 - kl_loss: 7.3453\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 2s 628ms/step - loss: 4721.1857 - reconstruction_loss: 4729.7354 - kl_loss: 7.5103\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4730.8913 - reconstruction_loss: 4718.5723 - kl_loss: 7.2302\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4723.4447 - reconstruction_loss: 4731.0635 - kl_loss: 7.4963\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 1s 646ms/step - loss: 4729.4227 - reconstruction_loss: 4720.7637 - kl_loss: 7.4977\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4732.5485 - reconstruction_loss: 4717.1997 - kl_loss: 7.1938\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 4735.4295 - reconstruction_loss: 4719.0732 - kl_loss: 7.4735\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 4734.6457 - reconstruction_loss: 4712.7886 - kl_loss: 7.2805\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4735.1930 - reconstruction_loss: 4714.3730 - kl_loss: 7.2457\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 2s 918ms/step - loss: 4725.9064 - reconstruction_loss: 4722.3926 - kl_loss: 7.1695\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4732.4355 - reconstruction_loss: 4715.0396 - kl_loss: 7.2465\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4730.6388 - reconstruction_loss: 4725.8750 - kl_loss: 7.2464\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4732.1548 - reconstruction_loss: 4717.9873 - kl_loss: 7.3922\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4734.0571 - reconstruction_loss: 4718.0811 - kl_loss: 7.2001\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4734.3691 - reconstruction_loss: 4714.5381 - kl_loss: 7.1436\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4728.7409 - reconstruction_loss: 4720.7695 - kl_loss: 7.2790\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 4726.8192 - reconstruction_loss: 4726.1968 - kl_loss: 7.1192\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 1s 775ms/step - loss: 4724.3555 - reconstruction_loss: 4725.3564 - kl_loss: 7.2651\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 2s 701ms/step - loss: 4730.8029 - reconstruction_loss: 4716.0952 - kl_loss: 7.2294\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 4724.2290 - reconstruction_loss: 4724.4873 - kl_loss: 7.0572\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4729.8595 - reconstruction_loss: 4720.8237 - kl_loss: 7.1783\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4732.5695 - reconstruction_loss: 4714.0107 - kl_loss: 7.0105\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 1s 603ms/step - loss: 4730.7588 - reconstruction_loss: 4718.6602 - kl_loss: 6.9751\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4722.0967 - reconstruction_loss: 4724.8867 - kl_loss: 7.1401\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4722.1567 - reconstruction_loss: 4725.6191 - kl_loss: 7.1331\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 4724.9237 - reconstruction_loss: 4722.1909 - kl_loss: 7.0188\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 2s 981ms/step - loss: 4725.9032 - reconstruction_loss: 4721.0029 - kl_loss: 7.1572\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 4722.9993 - reconstruction_loss: 4725.8677 - kl_loss: 7.0115\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 4723.1979 - reconstruction_loss: 4722.9307 - kl_loss: 6.9651\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4718.3198 - reconstruction_loss: 4730.5752 - kl_loss: 7.0725\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4729.3566 - reconstruction_loss: 4716.8936 - kl_loss: 6.8391\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4731.7275 - reconstruction_loss: 4712.9219 - kl_loss: 7.1015\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4726.4821 - reconstruction_loss: 4719.7412 - kl_loss: 6.8617\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4727.2183 - reconstruction_loss: 4717.1797 - kl_loss: 6.9245\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 1s 686ms/step - loss: 4729.7923 - reconstruction_loss: 4715.9619 - kl_loss: 7.0990\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 2s 759ms/step - loss: 4724.7952 - reconstruction_loss: 4720.7998 - kl_loss: 6.9522\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4724.9049 - reconstruction_loss: 4719.9604 - kl_loss: 6.8873\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 4728.0749 - reconstruction_loss: 4715.6650 - kl_loss: 6.9035\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4727.8026 - reconstruction_loss: 4718.0332 - kl_loss: 6.8268\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4737.9998 - reconstruction_loss: 4707.6172 - kl_loss: 6.7530\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4733.8011 - reconstruction_loss: 4712.5728 - kl_loss: 6.6132\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4720.2780 - reconstruction_loss: 4729.3530 - kl_loss: 7.0130\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4729.4881 - reconstruction_loss: 4715.4214 - kl_loss: 6.7682\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 2s 975ms/step - loss: 4732.7357 - reconstruction_loss: 4710.9839 - kl_loss: 6.7229\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 1s 652ms/step - loss: 4731.8009 - reconstruction_loss: 4711.6338 - kl_loss: 6.7722\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4729.1857 - reconstruction_loss: 4720.6445 - kl_loss: 6.6069\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4733.2295 - reconstruction_loss: 4710.0586 - kl_loss: 6.7146\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 1s 646ms/step - loss: 4717.2861 - reconstruction_loss: 4728.9062 - kl_loss: 6.9526\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4721.4622 - reconstruction_loss: 4723.2393 - kl_loss: 6.7269\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4727.3413 - reconstruction_loss: 4715.5537 - kl_loss: 6.6668\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 1s 658ms/step - loss: 4722.3654 - reconstruction_loss: 4723.0264 - kl_loss: 6.8743\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 1s 781ms/step - loss: 4717.7998 - reconstruction_loss: 4726.4658 - kl_loss: 6.7638\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 2s 691ms/step - loss: 4725.7441 - reconstruction_loss: 4717.2886 - kl_loss: 6.7490\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4724.2881 - reconstruction_loss: 4721.7480 - kl_loss: 6.8166\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4717.5716 - reconstruction_loss: 4728.3721 - kl_loss: 6.8058\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4720.2402 - reconstruction_loss: 4726.0757 - kl_loss: 6.6805\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 1s 646ms/step - loss: 4725.3854 - reconstruction_loss: 4719.1631 - kl_loss: 6.6467\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 1s 646ms/step - loss: 4726.7109 - reconstruction_loss: 4715.5918 - kl_loss: 6.6758\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4723.2581 - reconstruction_loss: 4720.5371 - kl_loss: 6.6736\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4721.0303 - reconstruction_loss: 4725.3516 - kl_loss: 6.6567\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 2s 915ms/step - loss: 4721.6156 - reconstruction_loss: 4725.1050 - kl_loss: 6.7905\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4729.2739 - reconstruction_loss: 4712.6460 - kl_loss: 6.6669\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 1s 641ms/step - loss: 4725.2541 - reconstruction_loss: 4718.3135 - kl_loss: 6.5982\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4716.5332 - reconstruction_loss: 4727.2246 - kl_loss: 6.7445\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4731.8301 - reconstruction_loss: 4707.7383 - kl_loss: 6.5374\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4724.6056 - reconstruction_loss: 4715.1377 - kl_loss: 6.5787\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 1s 653ms/step - loss: 4732.4010 - reconstruction_loss: 4706.9443 - kl_loss: 6.5224\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4715.8607 - reconstruction_loss: 4728.5918 - kl_loss: 6.6558\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 1s 754ms/step - loss: 4733.1182 - reconstruction_loss: 4706.4512 - kl_loss: 6.5016\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 2s 725ms/step - loss: 4728.0615 - reconstruction_loss: 4713.3438 - kl_loss: 6.4538\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 1s 648ms/step - loss: 4714.7752 - reconstruction_loss: 4726.9629 - kl_loss: 6.5034\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4725.4390 - reconstruction_loss: 4714.8896 - kl_loss: 6.4406\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4732.7684 - reconstruction_loss: 4706.1611 - kl_loss: 6.4279\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4730.0031 - reconstruction_loss: 4710.1089 - kl_loss: 6.3474\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4730.3908 - reconstruction_loss: 4709.9336 - kl_loss: 6.5413\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 4733.1436 - reconstruction_loss: 4705.5488 - kl_loss: 6.1903\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4717.1987 - reconstruction_loss: 4725.2119 - kl_loss: 6.4204\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 2s 961ms/step - loss: 4714.8543 - reconstruction_loss: 4727.2192 - kl_loss: 6.3044\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 1s 643ms/step - loss: 4718.4290 - reconstruction_loss: 4722.7422 - kl_loss: 6.4726\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4723.2093 - reconstruction_loss: 4718.0679 - kl_loss: 6.3678\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4724.2682 - reconstruction_loss: 4715.9424 - kl_loss: 6.3341\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4729.6572 - reconstruction_loss: 4708.4990 - kl_loss: 6.1339\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 1s 651ms/step - loss: 4723.5496 - reconstruction_loss: 4717.0146 - kl_loss: 6.3578\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4729.2119 - reconstruction_loss: 4713.0049 - kl_loss: 6.1118\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4715.5361 - reconstruction_loss: 4725.8584 - kl_loss: 6.3347\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 1s 792ms/step - loss: 4725.0000 - reconstruction_loss: 4714.9092 - kl_loss: 6.3465\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 2s 707ms/step - loss: 4717.9250 - reconstruction_loss: 4722.5312 - kl_loss: 6.2370\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 4714.4352 - reconstruction_loss: 4726.4419 - kl_loss: 6.3395\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4731.5549 - reconstruction_loss: 4709.2529 - kl_loss: 6.1623\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 1s 640ms/step - loss: 4726.1764 - reconstruction_loss: 4711.3965 - kl_loss: 6.3442\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 4731.4290 - reconstruction_loss: 4704.6558 - kl_loss: 6.1198\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4725.2531 - reconstruction_loss: 4712.7388 - kl_loss: 6.0317\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 1s 644ms/step - loss: 4720.9894 - reconstruction_loss: 4716.9551 - kl_loss: 6.0087\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4725.8574 - reconstruction_loss: 4713.2466 - kl_loss: 6.0142\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 2s 981ms/step - loss: 4716.9507 - reconstruction_loss: 4727.6543 - kl_loss: 6.2493\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 4721.8853 - reconstruction_loss: 4718.6406 - kl_loss: 6.1073\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4721.3748 - reconstruction_loss: 4719.6851 - kl_loss: 6.0706\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 4724.5260 - reconstruction_loss: 4714.9004 - kl_loss: 5.9233\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4721.7407 - reconstruction_loss: 4716.8760 - kl_loss: 6.1675\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4731.9224 - reconstruction_loss: 4704.6357 - kl_loss: 5.8168\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 1s 646ms/step - loss: 4715.6951 - reconstruction_loss: 4724.9727 - kl_loss: 6.1740\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4728.3805 - reconstruction_loss: 4710.5928 - kl_loss: 5.9350\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 1s 695ms/step - loss: 4728.4787 - reconstruction_loss: 4714.4785 - kl_loss: 5.9555\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 2s 758ms/step - loss: 4728.1532 - reconstruction_loss: 4709.5791 - kl_loss: 5.7823\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 4724.3478 - reconstruction_loss: 4711.6621 - kl_loss: 6.0179\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 4732.1313 - reconstruction_loss: 4708.5332 - kl_loss: 5.8812\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4718.5272 - reconstruction_loss: 4724.2236 - kl_loss: 6.1302\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4728.1216 - reconstruction_loss: 4713.9629 - kl_loss: 5.8306\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4723.7277 - reconstruction_loss: 4718.0649 - kl_loss: 6.0396\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 4726.0824 - reconstruction_loss: 4713.0947 - kl_loss: 5.9271\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 4714.9611 - reconstruction_loss: 4724.4268 - kl_loss: 6.0390\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 2s 944ms/step - loss: 4717.3309 - reconstruction_loss: 4721.7793 - kl_loss: 5.9616\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 2s 616ms/step - loss: 4731.4718 - reconstruction_loss: 4705.4688 - kl_loss: 5.6776\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4722.6626 - reconstruction_loss: 4716.2544 - kl_loss: 6.1281\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 4720.8356 - reconstruction_loss: 4718.3882 - kl_loss: 5.6985\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4724.6567 - reconstruction_loss: 4714.4854 - kl_loss: 5.8465\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4718.2310 - reconstruction_loss: 4725.2700 - kl_loss: 5.9498\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4722.8512 - reconstruction_loss: 4718.4004 - kl_loss: 5.6341\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 4721.1812 - reconstruction_loss: 4721.3711 - kl_loss: 5.9815\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4729.7482 - reconstruction_loss: 4705.2344 - kl_loss: 5.8158\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 2s 892ms/step - loss: 4720.6287 - reconstruction_loss: 4714.6865 - kl_loss: 5.9815\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4723.4811 - reconstruction_loss: 4713.6587 - kl_loss: 5.8699\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4717.8766 - reconstruction_loss: 4719.4229 - kl_loss: 6.0042\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 4730.7858 - reconstruction_loss: 4706.6782 - kl_loss: 5.9019\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4723.4660 - reconstruction_loss: 4712.4678 - kl_loss: 5.9357\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 1s 640ms/step - loss: 4727.6732 - reconstruction_loss: 4710.1484 - kl_loss: 5.9676\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4716.6349 - reconstruction_loss: 4721.1685 - kl_loss: 5.8558\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4721.8748 - reconstruction_loss: 4718.3213 - kl_loss: 5.8246\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 2s 870ms/step - loss: 4725.3421 - reconstruction_loss: 4712.9570 - kl_loss: 5.9842\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 2s 638ms/step - loss: 4717.7256 - reconstruction_loss: 4722.0420 - kl_loss: 5.7184\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4722.4287 - reconstruction_loss: 4717.8076 - kl_loss: 5.9154\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 1s 657ms/step - loss: 4722.8332 - reconstruction_loss: 4719.2510 - kl_loss: 5.5353\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 1s 650ms/step - loss: 4717.9645 - reconstruction_loss: 4717.6143 - kl_loss: 5.8003\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 2s 1s/step - loss: 4711.8158 - reconstruction_loss: 4724.0347 - kl_loss: 5.7150\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 2s 632ms/step - loss: 4714.0700 - reconstruction_loss: 4723.1201 - kl_loss: 5.8279\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 1s 641ms/step - loss: 4721.8577 - reconstruction_loss: 4717.2720 - kl_loss: 5.7046\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 2s 943ms/step - loss: 4721.0345 - reconstruction_loss: 4714.5825 - kl_loss: 5.5909\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4724.2725 - reconstruction_loss: 4712.2734 - kl_loss: 5.8596\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4713.5692 - reconstruction_loss: 4722.5938 - kl_loss: 5.7316\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4717.5692 - reconstruction_loss: 4716.5039 - kl_loss: 5.8543\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4714.1618 - reconstruction_loss: 4720.2988 - kl_loss: 5.7622\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 4718.5780 - reconstruction_loss: 4714.6104 - kl_loss: 5.8486\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4711.3167 - reconstruction_loss: 4724.1387 - kl_loss: 5.8555\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 1s 652ms/step - loss: 4727.0487 - reconstruction_loss: 4705.9170 - kl_loss: 5.6224\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 1s 742ms/step - loss: 4719.5422 - reconstruction_loss: 4717.1855 - kl_loss: 5.8437\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 2s 720ms/step - loss: 4731.0142 - reconstruction_loss: 4703.0811 - kl_loss: 5.5732\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4720.2132 - reconstruction_loss: 4720.2822 - kl_loss: 5.9056\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 4728.3252 - reconstruction_loss: 4710.6436 - kl_loss: 5.4522\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4731.2785 - reconstruction_loss: 4708.0498 - kl_loss: 5.9292\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 1s 640ms/step - loss: 4717.5269 - reconstruction_loss: 4723.7676 - kl_loss: 5.4829\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 4724.0758 - reconstruction_loss: 4718.4375 - kl_loss: 5.8035\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4728.5599 - reconstruction_loss: 4714.5273 - kl_loss: 5.7550\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4723.3058 - reconstruction_loss: 4714.5464 - kl_loss: 5.4513\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 4720.2772 - reconstruction_loss: 4716.8682 - kl_loss: 5.7595\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 2s 633ms/step - loss: 4727.7145 - reconstruction_loss: 4704.5537 - kl_loss: 5.6123\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4711.5314 - reconstruction_loss: 4725.1572 - kl_loss: 5.6407\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4719.4357 - reconstruction_loss: 4716.3945 - kl_loss: 5.6944\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4726.2266 - reconstruction_loss: 4707.0947 - kl_loss: 5.4590\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 1s 641ms/step - loss: 4712.2440 - reconstruction_loss: 4725.6509 - kl_loss: 5.8187\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4719.9263 - reconstruction_loss: 4715.4180 - kl_loss: 5.4712\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4721.2747 - reconstruction_loss: 4712.3228 - kl_loss: 5.7409\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 1s 647ms/step - loss: 4714.8911 - reconstruction_loss: 4715.9668 - kl_loss: 5.5031\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 2s 874ms/step - loss: 4712.1299 - reconstruction_loss: 4722.0771 - kl_loss: 5.5981\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4721.7077 - reconstruction_loss: 4708.7271 - kl_loss: 5.5730\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4721.2827 - reconstruction_loss: 4710.5996 - kl_loss: 5.6032\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4719.2896 - reconstruction_loss: 4713.0034 - kl_loss: 5.5702\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4714.5117 - reconstruction_loss: 4718.0576 - kl_loss: 5.6921\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4720.7036 - reconstruction_loss: 4711.2881 - kl_loss: 5.6322\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4709.2406 - reconstruction_loss: 4723.8018 - kl_loss: 5.5765\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 4717.1647 - reconstruction_loss: 4711.3789 - kl_loss: 5.5559\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 1s 807ms/step - loss: 4720.3503 - reconstruction_loss: 4709.8564 - kl_loss: 5.5653\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 2s 671ms/step - loss: 4727.3236 - reconstruction_loss: 4699.0947 - kl_loss: 5.5349\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4722.5788 - reconstruction_loss: 4705.9492 - kl_loss: 5.5668\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4716.0353 - reconstruction_loss: 4713.2168 - kl_loss: 5.4660\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 4713.4785 - reconstruction_loss: 4716.6152 - kl_loss: 5.5110\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 4716.5734 - reconstruction_loss: 4714.7803 - kl_loss: 5.4526\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4722.8293 - reconstruction_loss: 4703.8994 - kl_loss: 5.4175\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 1s 645ms/step - loss: 4718.9922 - reconstruction_loss: 4710.3965 - kl_loss: 5.4034\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 4727.4347 - reconstruction_loss: 4702.6914 - kl_loss: 5.5231\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 2s 950ms/step - loss: 4707.1885 - reconstruction_loss: 4720.5381 - kl_loss: 5.4967\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4713.2882 - reconstruction_loss: 4720.0244 - kl_loss: 5.4939\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4715.8208 - reconstruction_loss: 4719.9727 - kl_loss: 5.4112\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4719.3442 - reconstruction_loss: 4709.5151 - kl_loss: 5.3382\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4717.7964 - reconstruction_loss: 4714.2393 - kl_loss: 5.5274\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4718.3761 - reconstruction_loss: 4713.1890 - kl_loss: 5.3498\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4711.4427 - reconstruction_loss: 4718.7207 - kl_loss: 5.5051\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4708.0959 - reconstruction_loss: 4724.6201 - kl_loss: 5.3858\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 1s 719ms/step - loss: 4715.1908 - reconstruction_loss: 4717.2891 - kl_loss: 5.6014\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 2s 762ms/step - loss: 4716.4704 - reconstruction_loss: 4712.3369 - kl_loss: 5.4451\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4717.6875 - reconstruction_loss: 4709.3076 - kl_loss: 5.4311\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 4723.3828 - reconstruction_loss: 4701.9365 - kl_loss: 5.4315\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4709.2168 - reconstruction_loss: 4719.6094 - kl_loss: 5.4982\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4717.0552 - reconstruction_loss: 4707.9482 - kl_loss: 5.3904\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 4719.8905 - reconstruction_loss: 4706.8428 - kl_loss: 5.5985\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4710.5928 - reconstruction_loss: 4719.5605 - kl_loss: 5.5248\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4718.8376 - reconstruction_loss: 4710.2441 - kl_loss: 5.5130\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 2s 871ms/step - loss: 4713.4873 - reconstruction_loss: 4718.5518 - kl_loss: 5.4328\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 2s 630ms/step - loss: 4717.8200 - reconstruction_loss: 4708.0273 - kl_loss: 5.5165\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4720.2547 - reconstruction_loss: 4706.2026 - kl_loss: 5.5530\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 4720.2056 - reconstruction_loss: 4706.1714 - kl_loss: 5.4475\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 1s 644ms/step - loss: 4720.3434 - reconstruction_loss: 4707.6465 - kl_loss: 5.3864\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4719.4198 - reconstruction_loss: 4707.5923 - kl_loss: 5.4958\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4714.1344 - reconstruction_loss: 4714.8926 - kl_loss: 5.3605\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4723.8166 - reconstruction_loss: 4705.4165 - kl_loss: 5.6101\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4722.2244 - reconstruction_loss: 4706.6270 - kl_loss: 5.2978\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 2s 894ms/step - loss: 4715.7292 - reconstruction_loss: 4713.8926 - kl_loss: 5.6245\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4711.7892 - reconstruction_loss: 4719.3057 - kl_loss: 5.4041\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4717.1079 - reconstruction_loss: 4711.5059 - kl_loss: 5.6722\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4713.5454 - reconstruction_loss: 4714.1719 - kl_loss: 5.3246\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 1s 653ms/step - loss: 4719.1868 - reconstruction_loss: 4711.1782 - kl_loss: 5.5470\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4715.6017 - reconstruction_loss: 4714.4092 - kl_loss: 5.3445\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 4722.1193 - reconstruction_loss: 4708.1436 - kl_loss: 5.5190\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 4724.6873 - reconstruction_loss: 4707.8101 - kl_loss: 5.3661\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 2s 826ms/step - loss: 4719.4827 - reconstruction_loss: 4715.1562 - kl_loss: 5.6005\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 2s 634ms/step - loss: 4717.1823 - reconstruction_loss: 4728.2739 - kl_loss: 5.6644\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4734.2869 - reconstruction_loss: 4717.5156 - kl_loss: 5.1374\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4726.5254 - reconstruction_loss: 4725.9883 - kl_loss: 5.9268\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4731.3890 - reconstruction_loss: 4726.3433 - kl_loss: 5.0683\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4725.1886 - reconstruction_loss: 4715.4014 - kl_loss: 5.7031\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 1s 643ms/step - loss: 4716.4574 - reconstruction_loss: 4720.7314 - kl_loss: 5.2806\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 4727.5680 - reconstruction_loss: 4719.8286 - kl_loss: 5.1914\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4726.9648 - reconstruction_loss: 4715.5615 - kl_loss: 5.5114\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 2s 926ms/step - loss: 4719.5949 - reconstruction_loss: 4720.7378 - kl_loss: 4.9375\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4722.2572 - reconstruction_loss: 4712.5479 - kl_loss: 5.3641\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4716.7220 - reconstruction_loss: 4723.5303 - kl_loss: 5.1647\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4717.7464 - reconstruction_loss: 4713.5425 - kl_loss: 5.1397\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4708.8285 - reconstruction_loss: 4720.4658 - kl_loss: 5.4358\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4716.5049 - reconstruction_loss: 4726.8232 - kl_loss: 5.4226\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4721.3413 - reconstruction_loss: 4713.1772 - kl_loss: 5.6107\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4722.2858 - reconstruction_loss: 4714.2539 - kl_loss: 5.3620\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 1s 789ms/step - loss: 4713.0848 - reconstruction_loss: 4723.7334 - kl_loss: 5.7660\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 2s 672ms/step - loss: 4713.3657 - reconstruction_loss: 4710.8779 - kl_loss: 5.6383\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4719.4648 - reconstruction_loss: 4705.2163 - kl_loss: 5.6167\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4712.9888 - reconstruction_loss: 4716.9609 - kl_loss: 5.6092\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4716.5591 - reconstruction_loss: 4706.9639 - kl_loss: 5.7115\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4710.1517 - reconstruction_loss: 4713.2793 - kl_loss: 5.7903\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 4718.5192 - reconstruction_loss: 4704.6421 - kl_loss: 5.8996\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4709.5452 - reconstruction_loss: 4713.2666 - kl_loss: 5.7245\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4706.8488 - reconstruction_loss: 4717.3286 - kl_loss: 5.7977\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 2s 961ms/step - loss: 4714.5340 - reconstruction_loss: 4707.2773 - kl_loss: 5.7646\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 4717.6766 - reconstruction_loss: 4702.4248 - kl_loss: 5.8178\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 4716.4110 - reconstruction_loss: 4703.8452 - kl_loss: 5.6534\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 1s 646ms/step - loss: 4714.4790 - reconstruction_loss: 4707.0835 - kl_loss: 5.7623\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 1s 644ms/step - loss: 4707.1105 - reconstruction_loss: 4715.1074 - kl_loss: 5.6752\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 4705.2253 - reconstruction_loss: 4717.0825 - kl_loss: 5.6620\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4716.5394 - reconstruction_loss: 4703.6318 - kl_loss: 5.5977\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4716.3164 - reconstruction_loss: 4703.9917 - kl_loss: 5.5860\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 1s 729ms/step - loss: 4706.2661 - reconstruction_loss: 4716.1211 - kl_loss: 5.5824\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 2s 729ms/step - loss: 4706.6458 - reconstruction_loss: 4718.7490 - kl_loss: 5.4263\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 4714.4229 - reconstruction_loss: 4707.7739 - kl_loss: 5.6314\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 4709.2507 - reconstruction_loss: 4717.3828 - kl_loss: 5.3454\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4719.5785 - reconstruction_loss: 4703.0508 - kl_loss: 5.6365\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4724.2251 - reconstruction_loss: 4701.1016 - kl_loss: 5.3315\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4717.3091 - reconstruction_loss: 4705.7939 - kl_loss: 5.4362\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4719.7614 - reconstruction_loss: 4702.9409 - kl_loss: 5.4292\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 4710.3193 - reconstruction_loss: 4718.0625 - kl_loss: 5.3061\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 2s 881ms/step - loss: 4716.9137 - reconstruction_loss: 4707.5972 - kl_loss: 5.5827\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 2s 622ms/step - loss: 4719.1408 - reconstruction_loss: 4701.3145 - kl_loss: 5.3284\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4714.6211 - reconstruction_loss: 4706.6045 - kl_loss: 5.5919\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4707.8024 - reconstruction_loss: 4712.2314 - kl_loss: 5.4267\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4709.7705 - reconstruction_loss: 4710.4121 - kl_loss: 5.4513\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4714.4897 - reconstruction_loss: 4704.6084 - kl_loss: 5.4545\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4705.3226 - reconstruction_loss: 4717.4551 - kl_loss: 5.4466\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 4711.7051 - reconstruction_loss: 4709.6362 - kl_loss: 5.4843\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4712.2432 - reconstruction_loss: 4709.1904 - kl_loss: 5.4450\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 2s 919ms/step - loss: 4712.6195 - reconstruction_loss: 4707.0518 - kl_loss: 5.4228\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 1s 647ms/step - loss: 4724.9321 - reconstruction_loss: 4695.8838 - kl_loss: 5.3573\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4709.1187 - reconstruction_loss: 4715.1646 - kl_loss: 5.4947\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4711.4398 - reconstruction_loss: 4709.6021 - kl_loss: 5.2643\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4711.3034 - reconstruction_loss: 4709.1763 - kl_loss: 5.4615\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4710.1519 - reconstruction_loss: 4708.6074 - kl_loss: 5.4484\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4721.7725 - reconstruction_loss: 4693.8330 - kl_loss: 5.4032\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 1s 611ms/step - loss: 4712.7715 - reconstruction_loss: 4705.4087 - kl_loss: 5.5101\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 2s 827ms/step - loss: 4706.1009 - reconstruction_loss: 4716.0723 - kl_loss: 5.3684\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 2s 626ms/step - loss: 4716.0037 - reconstruction_loss: 4706.0117 - kl_loss: 5.5176\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4721.0412 - reconstruction_loss: 4699.9380 - kl_loss: 5.2887\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 1s 663ms/step - loss: 4725.8270 - reconstruction_loss: 4710.6016 - kl_loss: 5.6210\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4729.3328 - reconstruction_loss: 4711.9570 - kl_loss: 5.1312\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4721.4362 - reconstruction_loss: 4719.8457 - kl_loss: 5.8528\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 4719.8740 - reconstruction_loss: 4707.7109 - kl_loss: 5.2465\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4722.1632 - reconstruction_loss: 4714.1191 - kl_loss: 5.4325\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4720.4250 - reconstruction_loss: 4708.5176 - kl_loss: 5.3752\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 2s 942ms/step - loss: 4721.6556 - reconstruction_loss: 4710.7588 - kl_loss: 5.3473\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4724.8335 - reconstruction_loss: 4708.6133 - kl_loss: 5.5738\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 1s 641ms/step - loss: 4714.5430 - reconstruction_loss: 4714.6899 - kl_loss: 5.0762\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4711.8320 - reconstruction_loss: 4708.0752 - kl_loss: 5.3544\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 4716.0718 - reconstruction_loss: 4711.1152 - kl_loss: 5.3747\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4713.0404 - reconstruction_loss: 4707.9346 - kl_loss: 5.3058\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4718.6411 - reconstruction_loss: 4697.0312 - kl_loss: 5.5889\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 1s 650ms/step - loss: 4713.1042 - reconstruction_loss: 4707.8018 - kl_loss: 5.5636\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 2s 822ms/step - loss: 4715.1338 - reconstruction_loss: 4703.2583 - kl_loss: 5.6786\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 2s 654ms/step - loss: 4723.4849 - reconstruction_loss: 4692.9429 - kl_loss: 5.4859\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4713.2184 - reconstruction_loss: 4703.5000 - kl_loss: 5.5580\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4706.4307 - reconstruction_loss: 4712.6729 - kl_loss: 5.4136\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4718.6188 - reconstruction_loss: 4696.5557 - kl_loss: 5.5595\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4714.4434 - reconstruction_loss: 4700.7930 - kl_loss: 5.5563\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4714.6307 - reconstruction_loss: 4701.8149 - kl_loss: 5.5194\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4711.9712 - reconstruction_loss: 4705.8989 - kl_loss: 5.4261\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4720.5407 - reconstruction_loss: 4692.8438 - kl_loss: 5.4984\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 2s 971ms/step - loss: 4709.4933 - reconstruction_loss: 4706.7324 - kl_loss: 5.3341\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4707.4902 - reconstruction_loss: 4709.9512 - kl_loss: 5.5700\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 1s 640ms/step - loss: 4704.0246 - reconstruction_loss: 4716.3296 - kl_loss: 5.3368\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4709.3563 - reconstruction_loss: 4713.2344 - kl_loss: 5.2371\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 4707.5454 - reconstruction_loss: 4711.5293 - kl_loss: 5.4083\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4713.6029 - reconstruction_loss: 4705.6167 - kl_loss: 5.2989\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4708.6678 - reconstruction_loss: 4706.4771 - kl_loss: 5.4082\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 1s 648ms/step - loss: 4708.1336 - reconstruction_loss: 4707.8975 - kl_loss: 5.3883\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 2s 824ms/step - loss: 4721.6012 - reconstruction_loss: 4690.6611 - kl_loss: 5.5633\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 2s 669ms/step - loss: 4704.9956 - reconstruction_loss: 4710.2197 - kl_loss: 5.3495\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 1s 653ms/step - loss: 4712.6958 - reconstruction_loss: 4701.3086 - kl_loss: 5.3865\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 1s 648ms/step - loss: 4705.0241 - reconstruction_loss: 4709.8965 - kl_loss: 5.5012\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 1s 643ms/step - loss: 4703.4287 - reconstruction_loss: 4712.6899 - kl_loss: 5.3368\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4703.6688 - reconstruction_loss: 4713.0869 - kl_loss: 5.4416\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4708.9334 - reconstruction_loss: 4706.4600 - kl_loss: 5.3533\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4705.2388 - reconstruction_loss: 4712.7783 - kl_loss: 5.4825\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4704.0457 - reconstruction_loss: 4712.6699 - kl_loss: 5.2898\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 2s 939ms/step - loss: 4711.1366 - reconstruction_loss: 4705.5098 - kl_loss: 5.4446\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 4704.9401 - reconstruction_loss: 4713.3013 - kl_loss: 5.1803\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4707.1735 - reconstruction_loss: 4711.6387 - kl_loss: 5.3503\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4702.4849 - reconstruction_loss: 4714.0605 - kl_loss: 5.1815\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4713.8110 - reconstruction_loss: 4711.6440 - kl_loss: 5.0926\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 4715.2433 - reconstruction_loss: 4708.9434 - kl_loss: 5.4452\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4720.3594 - reconstruction_loss: 4707.0303 - kl_loss: 4.9470\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 1s 644ms/step - loss: 4712.8853 - reconstruction_loss: 4717.5098 - kl_loss: 5.4726\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 2s 879ms/step - loss: 4712.8595 - reconstruction_loss: 4709.2949 - kl_loss: 4.9982\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 2s 634ms/step - loss: 4715.6439 - reconstruction_loss: 4703.1504 - kl_loss: 5.2917\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4710.1641 - reconstruction_loss: 4709.8506 - kl_loss: 5.2012\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4708.3094 - reconstruction_loss: 4705.9648 - kl_loss: 5.2721\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4711.0168 - reconstruction_loss: 4702.4272 - kl_loss: 5.3767\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4711.9250 - reconstruction_loss: 4701.4819 - kl_loss: 5.2720\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4705.9941 - reconstruction_loss: 4707.6602 - kl_loss: 5.3274\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4711.0005 - reconstruction_loss: 4700.8682 - kl_loss: 5.3892\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4706.2767 - reconstruction_loss: 4706.5635 - kl_loss: 5.4815\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 2s 941ms/step - loss: 4716.8978 - reconstruction_loss: 4692.7109 - kl_loss: 5.4253\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4706.3441 - reconstruction_loss: 4705.0078 - kl_loss: 5.3894\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 1s 622ms/step - loss: 4713.9123 - reconstruction_loss: 4699.2881 - kl_loss: 5.4386\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 1s 645ms/step - loss: 4701.6367 - reconstruction_loss: 4713.0400 - kl_loss: 5.3062\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4698.7417 - reconstruction_loss: 4715.0137 - kl_loss: 5.3462\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 4718.7563 - reconstruction_loss: 4693.7251 - kl_loss: 5.4191\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4714.0317 - reconstruction_loss: 4694.9824 - kl_loss: 5.4546\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 1s 660ms/step - loss: 4702.3779 - reconstruction_loss: 4709.4902 - kl_loss: 5.4142\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 2s 934ms/step - loss: 4701.4937 - reconstruction_loss: 4711.8516 - kl_loss: 5.2945\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 2s 651ms/step - loss: 4715.0418 - reconstruction_loss: 4698.9380 - kl_loss: 5.3317\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 4711.5951 - reconstruction_loss: 4702.0977 - kl_loss: 5.4664\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 4717.1385 - reconstruction_loss: 4695.1646 - kl_loss: 5.3153\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4715.7020 - reconstruction_loss: 4697.3491 - kl_loss: 5.4562\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4713.0755 - reconstruction_loss: 4696.7637 - kl_loss: 5.2396\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4714.3843 - reconstruction_loss: 4694.8594 - kl_loss: 5.3925\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4707.1423 - reconstruction_loss: 4703.2720 - kl_loss: 5.3184\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4699.1898 - reconstruction_loss: 4714.1021 - kl_loss: 5.3766\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 4706.3853 - reconstruction_loss: 4705.9492 - kl_loss: 5.2242\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4718.7749 - reconstruction_loss: 4690.8984 - kl_loss: 5.4573\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4710.7705 - reconstruction_loss: 4701.4331 - kl_loss: 5.1397\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4718.0578 - reconstruction_loss: 4692.0830 - kl_loss: 5.3719\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4711.5124 - reconstruction_loss: 4699.7266 - kl_loss: 5.3145\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4702.2972 - reconstruction_loss: 4709.8652 - kl_loss: 5.4186\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4708.4689 - reconstruction_loss: 4702.9629 - kl_loss: 5.3424\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4716.3547 - reconstruction_loss: 4691.7393 - kl_loss: 5.3750\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 2s 836ms/step - loss: 4703.3608 - reconstruction_loss: 4709.7783 - kl_loss: 5.2838\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 2s 641ms/step - loss: 4718.3109 - reconstruction_loss: 4692.7197 - kl_loss: 5.3720\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 1s 651ms/step - loss: 4715.2502 - reconstruction_loss: 4695.1333 - kl_loss: 5.2220\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4708.3275 - reconstruction_loss: 4707.0947 - kl_loss: 5.4811\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4710.7472 - reconstruction_loss: 4708.0186 - kl_loss: 5.1315\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 4710.2075 - reconstruction_loss: 4704.0713 - kl_loss: 5.3218\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 1s 624ms/step - loss: 4706.9808 - reconstruction_loss: 4707.8970 - kl_loss: 5.1277\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 4706.4183 - reconstruction_loss: 4706.4775 - kl_loss: 5.2708\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 4706.8708 - reconstruction_loss: 4706.7676 - kl_loss: 5.2890\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 2s 899ms/step - loss: 4718.7523 - reconstruction_loss: 4692.1406 - kl_loss: 5.1432\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 1s 651ms/step - loss: 4716.0734 - reconstruction_loss: 4694.2793 - kl_loss: 5.3394\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4711.9339 - reconstruction_loss: 4698.4434 - kl_loss: 5.1469\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4711.5677 - reconstruction_loss: 4702.2061 - kl_loss: 5.3181\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4712.1159 - reconstruction_loss: 4704.4102 - kl_loss: 4.9961\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 1s 641ms/step - loss: 4703.9840 - reconstruction_loss: 4712.2959 - kl_loss: 5.3208\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 4706.6263 - reconstruction_loss: 4710.4756 - kl_loss: 5.0188\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4710.2104 - reconstruction_loss: 4707.6855 - kl_loss: 5.3945\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 2s 849ms/step - loss: 4713.9191 - reconstruction_loss: 4699.3682 - kl_loss: 5.0745\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 2s 667ms/step - loss: 4706.7148 - reconstruction_loss: 4704.1431 - kl_loss: 5.3399\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4702.5166 - reconstruction_loss: 4712.2773 - kl_loss: 5.2635\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 4716.8820 - reconstruction_loss: 4694.2969 - kl_loss: 5.2722\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4705.4956 - reconstruction_loss: 4707.6748 - kl_loss: 5.4103\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4704.8859 - reconstruction_loss: 4704.6973 - kl_loss: 5.2630\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 1s 647ms/step - loss: 4703.5015 - reconstruction_loss: 4704.9722 - kl_loss: 5.3367\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4707.3942 - reconstruction_loss: 4702.7817 - kl_loss: 5.1410\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 1s 640ms/step - loss: 4710.0451 - reconstruction_loss: 4700.0605 - kl_loss: 5.3437\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 2s 934ms/step - loss: 4709.0615 - reconstruction_loss: 4700.2104 - kl_loss: 5.2078\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4701.3634 - reconstruction_loss: 4709.0195 - kl_loss: 5.2852\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 1s 643ms/step - loss: 4700.2077 - reconstruction_loss: 4709.0332 - kl_loss: 5.2848\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 4698.0973 - reconstruction_loss: 4713.5908 - kl_loss: 5.3552\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 4700.3918 - reconstruction_loss: 4708.1387 - kl_loss: 5.1145\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4708.7604 - reconstruction_loss: 4697.5137 - kl_loss: 5.2200\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 1s 656ms/step - loss: 4708.9202 - reconstruction_loss: 4697.8066 - kl_loss: 5.2523\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 1s 628ms/step - loss: 4703.2599 - reconstruction_loss: 4704.9624 - kl_loss: 5.2071\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 2s 836ms/step - loss: 4711.5703 - reconstruction_loss: 4699.4263 - kl_loss: 5.2582\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 2s 641ms/step - loss: 4706.0651 - reconstruction_loss: 4707.7910 - kl_loss: 5.0243\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4706.9136 - reconstruction_loss: 4710.6523 - kl_loss: 5.3228\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 1s 637ms/step - loss: 4711.7174 - reconstruction_loss: 4704.6885 - kl_loss: 4.9474\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4706.8797 - reconstruction_loss: 4708.3613 - kl_loss: 5.3902\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 1s 646ms/step - loss: 4701.3945 - reconstruction_loss: 4710.1445 - kl_loss: 4.9445\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 1s 636ms/step - loss: 4704.7303 - reconstruction_loss: 4705.4785 - kl_loss: 5.0617\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 4700.5791 - reconstruction_loss: 4705.7930 - kl_loss: 5.1325\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4707.6738 - reconstruction_loss: 4700.5781 - kl_loss: 5.3059\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 2s 913ms/step - loss: 4705.0348 - reconstruction_loss: 4704.1064 - kl_loss: 5.2535\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 4703.5819 - reconstruction_loss: 4702.4692 - kl_loss: 5.2705\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 1s 638ms/step - loss: 4695.5677 - reconstruction_loss: 4713.1914 - kl_loss: 5.2755\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 1s 626ms/step - loss: 4702.7544 - reconstruction_loss: 4706.4688 - kl_loss: 5.4048\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 1s 641ms/step - loss: 4707.8423 - reconstruction_loss: 4699.6719 - kl_loss: 5.3488\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 1s 631ms/step - loss: 4712.0942 - reconstruction_loss: 4693.5479 - kl_loss: 5.3819\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4698.2370 - reconstruction_loss: 4710.3848 - kl_loss: 5.2022\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 1s 633ms/step - loss: 4696.0197 - reconstruction_loss: 4713.0010 - kl_loss: 5.4184\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 1s 799ms/step - loss: 4700.1090 - reconstruction_loss: 4708.2856 - kl_loss: 5.2670\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 2s 706ms/step - loss: 4706.4759 - reconstruction_loss: 4700.3340 - kl_loss: 5.3952\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 4708.1961 - reconstruction_loss: 4695.9160 - kl_loss: 5.3017\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 1s 644ms/step - loss: 4696.1336 - reconstruction_loss: 4709.5381 - kl_loss: 5.5127\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4701.1143 - reconstruction_loss: 4704.3643 - kl_loss: 5.3892\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 1s 640ms/step - loss: 4711.0693 - reconstruction_loss: 4691.0063 - kl_loss: 5.4333\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 4704.6681 - reconstruction_loss: 4699.2900 - kl_loss: 5.3822\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4711.7975 - reconstruction_loss: 4691.7002 - kl_loss: 5.3260\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 1s 627ms/step - loss: 4703.4578 - reconstruction_loss: 4701.1621 - kl_loss: 5.3441\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 2s 969ms/step - loss: 4717.1776 - reconstruction_loss: 4686.6099 - kl_loss: 5.2357\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 4697.5609 - reconstruction_loss: 4708.1704 - kl_loss: 5.2770\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 1s 643ms/step - loss: 4697.6266 - reconstruction_loss: 4707.4697 - kl_loss: 5.2811\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 1s 650ms/step - loss: 4702.9425 - reconstruction_loss: 4701.6006 - kl_loss: 5.3140\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4706.6242 - reconstruction_loss: 4696.7725 - kl_loss: 5.1696\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4711.1510 - reconstruction_loss: 4689.9253 - kl_loss: 5.2899\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4704.7531 - reconstruction_loss: 4698.7197 - kl_loss: 5.1757\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 4708.4010 - reconstruction_loss: 4696.0405 - kl_loss: 5.2742\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 1s 752ms/step - loss: 4697.8755 - reconstruction_loss: 4706.2637 - kl_loss: 5.2205\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 2s 692ms/step - loss: 4707.6201 - reconstruction_loss: 4698.2886 - kl_loss: 5.2848\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 1s 621ms/step - loss: 4699.8698 - reconstruction_loss: 4705.7622 - kl_loss: 5.1874\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 1s 635ms/step - loss: 4705.4141 - reconstruction_loss: 4702.4224 - kl_loss: 5.3311\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 1s 619ms/step - loss: 4707.1696 - reconstruction_loss: 4709.5249 - kl_loss: 5.2261\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 3s 2s/step - loss: 4706.5036 - reconstruction_loss: 4701.1729 - kl_loss: 5.2522\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4715.2664 - reconstruction_loss: 4692.2812 - kl_loss: 5.1498\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 4s 2s/step - loss: 4702.6515 - reconstruction_loss: 4700.5684 - kl_loss: 5.2025\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 2s 807ms/step - loss: 4707.0856 - reconstruction_loss: 4698.8027 - kl_loss: 5.1897\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 4707.0296 - reconstruction_loss: 4695.7212 - kl_loss: 5.3842\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 1s 639ms/step - loss: 4705.5778 - reconstruction_loss: 4704.0361 - kl_loss: 5.1929\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 1s 642ms/step - loss: 4701.8460 - reconstruction_loss: 4712.7158 - kl_loss: 5.1657\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 1s 620ms/step - loss: 4708.0853 - reconstruction_loss: 4701.3506 - kl_loss: 4.9034\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimation of euclidian distance in the binary clusters"
      ],
      "metadata": {
        "id": "5dw4BADBwzQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "length = len(y_train)\n",
        "\n",
        "for i in range(0, length, 1):\n",
        "    b = np.reshape(x_train[i], (1, n_dim, n_dim, 1))\n",
        "    z_mean, _, _ = vae.encoder.predict(b)\n",
        "    c = np.array([[z_mean[:, 0], z_mean[:, 1]]])\n",
        "    c = np.reshape(c, (2, 1))\n",
        "    c = np.transpose(c)\n",
        "    data.append(c)\n",
        "\n",
        "data = np.array(data)\n",
        "data = np.reshape(data, (length, 2))\n",
        "y_train_label = np.reshape(y_train, (length, 1))\n",
        "data = np.concatenate((data, y_train_label), axis=1)\n",
        "means_cluster_1 = data[0:int(length/2), :2].mean(axis=0)\n",
        "means_cluster_2 = data[int(length/2):length+1, :2].mean(axis=0)\n",
        "dist = np.linalg.norm(means_cluster_1-means_cluster_2)\n",
        "print(\"Euclidian distance is \", dist)"
      ],
      "metadata": {
        "id": "80pLH78Lww0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}